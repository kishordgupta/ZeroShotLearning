{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZSL.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-VoekT4GEmj",
        "outputId": "2805e5ad-7c4e-4c5e-8139-e4888d9e1e6b"
      },
      "source": [
        "pip install np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting np_utils\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/18/5704a782fd72727a9e63198fcc76fadb86975f45bcdf579c10f668329508/np_utils-0.5.12.1.tar.gz (61kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n",
            "Building wheels for collected packages: np-utils\n",
            "  Building wheel for np-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np-utils: filename=np_utils-0.5.12.1-cp37-none-any.whl size=57133 sha256=7303b16c6c189e607703e8db56edd3b3dbc685879cf7c415d2e5ba9ba61848d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/4b/81/206efd0d01330a96f3aebe5021d2d5f0b264b7ade827c306ef\n",
            "Successfully built np-utils\n",
            "Installing collected packages: np-utils\n",
            "Successfully installed np-utils-0.5.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifD53SVUGJi3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVWed83fFmNW"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.tools import freeze_graph, optimize_for_inference_lib\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    vgg_model = keras.applications.VGG16(include_top=True, weights='imagenet')\n",
        "    vgg_model.layers.pop()\n",
        "    vgg_model.layers.pop()\n",
        "\n",
        "    inp = vgg_model.input\n",
        "    out = vgg_model.layers[-1].output\n",
        "\n",
        "    model = Model(inp, out)\n",
        "    return model\n",
        "\n",
        "def get_features(model, cropped_image):\n",
        "    x = image.img_to_array(cropped_image)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = keras.applications.vgg16.preprocess_input(x)\n",
        "    features = model.predict(x)\n",
        "    return features"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnaZOtM4By0I",
        "outputId": "f1ae5d95-1cf8-4fa6-b310-6d530da2698f"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(123)\n",
        "import gzip\n",
        "import _pickle as cPickle\n",
        "import os\n",
        "from collections import Counter\n",
        "from __future__ import absolute_import\n",
        "from sklearn.preprocessing import LabelEncoder, normalize\n",
        "from sklearn.neighbors import KDTree\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model, model_from_json\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "WORD2VECPATH    = \"./drive/MyDrive/zero-shot-learning-master/ZSL/data/class_vectors.npy\"\n",
        "DATAPATH        = \"./drive/MyDrive/zero-shot-learning-master/ZSL/data/zeroshot_data.pkl\"\n",
        "MODELPATH       = \"./drive/MyDrive/zero-shot-learning-master/ZSL/model/\"\n",
        "\n",
        "def load_keras_model(model_path):\n",
        "    with open(model_path +\"model.json\", 'r') as json_file:\n",
        "        loaded_model_json = json_file.read()\n",
        "\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(model_path+\"model.h5\")\n",
        "    return loaded_model\n",
        "\n",
        "def save_keras_model(model, model_path):\n",
        "    \"\"\"save Keras model and its weights\"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        os.makedirs(model_path)\n",
        "\n",
        "    model_json = model.to_json()\n",
        "    with open(model_path + \"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(model_path + \"model.h5\")\n",
        "    print(\"-> zsl model is saved.\")\n",
        "    return\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"read data, create datasets\"\"\"\n",
        "    # READ DATA\n",
        "    with gzip.GzipFile(DATAPATH, 'rb') as infile:\n",
        "        data = cPickle.load(infile)\n",
        "\n",
        "    # ONE-HOT-ENCODE DATA\n",
        "    label_encoder   = LabelEncoder()\n",
        "    label_encoder.fit(train_classes)\n",
        "\n",
        "    training_data = [instance for instance in data if instance[0] in train_classes]\n",
        "    zero_shot_data = [instance for instance in data if instance[0] not in train_classes]\n",
        "    # SHUFFLE TRAINING DATA\n",
        "    np.random.shuffle(training_data)\n",
        "\n",
        "    ### SPLIT DATA FOR TRAINING\n",
        "    train_size  = 300\n",
        "    train_data  = list()\n",
        "    valid_data  = list()\n",
        "    for class_label in train_classes:\n",
        "        ct = 0\n",
        "        for instance in training_data:\n",
        "            if instance[0] == class_label:\n",
        "                if ct < train_size:\n",
        "                    train_data.append(instance)\n",
        "                    ct+=1\n",
        "                    continue\n",
        "                valid_data.append(instance)\n",
        "\n",
        "    # SHUFFLE TRAINING AND VALIDATION DATA\n",
        "    np.random.shuffle(train_data)\n",
        "    np.random.shuffle(valid_data)\n",
        "\n",
        "    train_data = [(instance[1], tf.keras.utils.to_categorical(label_encoder.transform([instance[0]]), num_classes=15))for instance in train_data]\n",
        "    valid_data = [(instance[1], tf.keras.utils.to_categorical(label_encoder.transform([instance[0]]), num_classes=15)) for instance in valid_data]\n",
        "\n",
        "    # FORM X_TRAIN AND Y_TRAIN\n",
        "    x_train, y_train    = zip(*train_data)\n",
        "    x_train, y_train    = np.squeeze(np.asarray(x_train)), np.squeeze(np.asarray(y_train))\n",
        "    # L2 NORMALIZE X_TRAIN\n",
        "    x_train = normalize(x_train, norm='l2')\n",
        "\n",
        "    # FORM X_VALID AND Y_VALID\n",
        "    x_valid, y_valid = zip(*valid_data)\n",
        "    x_valid, y_valid = np.squeeze(np.asarray(x_valid)), np.squeeze(np.asarray(y_valid))\n",
        "    # L2 NORMALIZE X_VALID\n",
        "    x_valid = normalize(x_valid, norm='l2')\n",
        "\n",
        "\n",
        "    # FORM X_ZSL AND Y_ZSL\n",
        "    y_zsl, x_zsl = zip(*zero_shot_data)\n",
        "    x_zsl, y_zsl = np.squeeze(np.asarray(x_zsl)), np.squeeze(np.asarray(y_zsl))\n",
        "    # L2 NORMALIZE X_ZSL\n",
        "    x_zsl = normalize(x_zsl, norm='l2')\n",
        "\n",
        "    print(\"-> data loading is completed.\")\n",
        "    return (x_train, x_valid, x_zsl), (y_train, y_valid, y_zsl)\n",
        "\n",
        "\n",
        "def custom_kernel_init(shape,dtype=None):\n",
        "    class_vectors       = np.load(WORD2VECPATH, allow_pickle=True)\n",
        "    training_vectors    = sorted([(label, vec) for (label, vec) in class_vectors if label in train_classes], key=lambda x: x[0])\n",
        "    classnames, vectors = zip(*training_vectors)\n",
        "    vectors             = np.asarray(vectors, dtype=np.float)\n",
        "    vectors             = vectors.T\n",
        "    return vectors\n",
        "\n",
        "def  build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, input_shape=(4096,), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.8))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(NUM_ATTR, activation='relu'))\n",
        "    model.add(Dense(NUM_CLASS, activation='softmax', trainable=False, kernel_initializer=(custom_kernel_init)))\n",
        "\n",
        "    print(\"-> model building is completed.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, train_data, valid_data):\n",
        "    x_train, y_train = train_data\n",
        "    x_valid, y_valid = valid_data\n",
        "    adam = Adam(lr=5e-5)\n",
        "    model.compile(loss      = 'categorical_crossentropy',\n",
        "                  optimizer = adam,\n",
        "                  metrics   = ['categorical_accuracy', 'top_k_categorical_accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        validation_data = (x_valid, y_valid),\n",
        "                        verbose         = 2,\n",
        "                        epochs          = EPOCH,\n",
        "                        batch_size      = BATCH_SIZE,\n",
        "                        shuffle         = True)\n",
        "\n",
        "    print(\"model training is completed.\")\n",
        "    return history\n",
        "\n",
        "def main():\n",
        "\n",
        "    global train_classes\n",
        "    with open('./drive/MyDrive/zero-shot-learning-master/ZSL/src/train_classes.txt', 'r') as infile:\n",
        "        train_classes = [str.strip(line) for line in infile]\n",
        "\n",
        "    global zsl_classes\n",
        "    with open('./drive/MyDrive/zero-shot-learning-master/ZSL/src/zsl_classes.txt', 'r') as infile:\n",
        "        zsl_classes = [str.strip(line) for line in infile]\n",
        "\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # SET HYPERPARAMETERS\n",
        "\n",
        "    global NUM_CLASS, NUM_ATTR, EPOCH, BATCH_SIZE\n",
        "    NUM_CLASS = 15\n",
        "    NUM_ATTR = 300\n",
        "    BATCH_SIZE = 128\n",
        "    EPOCH = 65\n",
        "\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # TRAINING PHASE\n",
        "\n",
        "    (x_train, x_valid, x_zsl), (y_train, y_valid, y_zsl) = load_data()\n",
        "    model = build_model()\n",
        "    train_model(model, (x_train, y_train), (x_valid, y_valid))\n",
        "    print(model.summary())\n",
        "\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # CREATE AND SAVE ZSL MODEL\n",
        "\n",
        "    inp         = model.input\n",
        "    out         = model.layers[-2].output\n",
        "    zsl_model   = Model(inp, out)\n",
        "    print(zsl_model.summary())\n",
        "    save_keras_model(zsl_model, model_path=MODELPATH)\n",
        "\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # ---------------------------------------------------------------------------------------------------------------- #\n",
        "    # EVALUATION OF ZERO-SHOT LEARNING PERFORMANCE\n",
        "    #(x_train, x_valid, x_zsl), (y_train, y_valid, y_zsl) = load_data()\n",
        "    #zsl_model = load_keras_model(model_path=MODELPATH)\n",
        "\n",
        "    class_vectors       = sorted(np.load(WORD2VECPATH, allow_pickle=True), key=lambda x: x[0])\n",
        "    classnames, vectors = zip(*class_vectors)\n",
        "    classnames          = list(classnames)\n",
        "    vectors             = np.asarray(vectors, dtype=np.float)\n",
        "\n",
        "    tree        = KDTree(vectors)\n",
        "    pred_zsl    = zsl_model.predict(x_zsl)\n",
        "\n",
        "    top5, top3, top1 = 0, 0, 0\n",
        "    for i, pred in enumerate(pred_zsl):\n",
        "        pred            = np.expand_dims(pred, axis=0)\n",
        "        dist_5, index_5 = tree.query(pred, k=5)\n",
        "        pred_labels     = [classnames[index] for index in index_5[0]]\n",
        "        true_label      = y_zsl[i]\n",
        "        if true_label in pred_labels:\n",
        "            top5 += 1\n",
        "        if true_label in pred_labels[:3]:\n",
        "            top3 += 1\n",
        "        if true_label in pred_labels[0]:\n",
        "            top1 += 1\n",
        "\n",
        "    print()\n",
        "    print(\"ZERO SHOT LEARNING SCORE\")\n",
        "    print(\"-> Top-5 Accuracy: %.2f\" % (top5 / float(len(x_zsl))))\n",
        "    print(\"-> Top-3 Accuracy: %.2f\" % (top3 / float(len(x_zsl))))\n",
        "    print(\"-> Top-1 Accuracy: %.2f\" % (top1 / float(len(x_zsl))))\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-> data loading is completed.\n",
            "-> model building is completed.\n",
            "Epoch 1/65\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "36/36 - 1s - loss: 2.9035 - categorical_accuracy: 0.0929 - top_k_categorical_accuracy: 0.3844 - val_loss: 2.6986 - val_categorical_accuracy: 0.2096 - val_top_k_categorical_accuracy: 0.6229\n",
            "Epoch 2/65\n",
            "36/36 - 0s - loss: 2.6020 - categorical_accuracy: 0.1509 - top_k_categorical_accuracy: 0.5176 - val_loss: 2.6867 - val_categorical_accuracy: 0.2914 - val_top_k_categorical_accuracy: 0.7435\n",
            "Epoch 3/65\n",
            "36/36 - 0s - loss: 2.4403 - categorical_accuracy: 0.1969 - top_k_categorical_accuracy: 0.6051 - val_loss: 2.6669 - val_categorical_accuracy: 0.3322 - val_top_k_categorical_accuracy: 0.8031\n",
            "Epoch 4/65\n",
            "36/36 - 0s - loss: 2.2781 - categorical_accuracy: 0.2440 - top_k_categorical_accuracy: 0.6729 - val_loss: 2.6354 - val_categorical_accuracy: 0.3657 - val_top_k_categorical_accuracy: 0.8446\n",
            "Epoch 5/65\n",
            "36/36 - 0s - loss: 2.1021 - categorical_accuracy: 0.2896 - top_k_categorical_accuracy: 0.7387 - val_loss: 2.5912 - val_categorical_accuracy: 0.3918 - val_top_k_categorical_accuracy: 0.8607\n",
            "Epoch 6/65\n",
            "36/36 - 0s - loss: 1.9882 - categorical_accuracy: 0.3182 - top_k_categorical_accuracy: 0.7767 - val_loss: 2.5330 - val_categorical_accuracy: 0.4066 - val_top_k_categorical_accuracy: 0.8848\n",
            "Epoch 7/65\n",
            "36/36 - 0s - loss: 1.8819 - categorical_accuracy: 0.3413 - top_k_categorical_accuracy: 0.7996 - val_loss: 2.4617 - val_categorical_accuracy: 0.4307 - val_top_k_categorical_accuracy: 0.8975\n",
            "Epoch 8/65\n",
            "36/36 - 0s - loss: 1.8093 - categorical_accuracy: 0.3540 - top_k_categorical_accuracy: 0.8307 - val_loss: 2.3810 - val_categorical_accuracy: 0.4601 - val_top_k_categorical_accuracy: 0.9082\n",
            "Epoch 9/65\n",
            "36/36 - 0s - loss: 1.7432 - categorical_accuracy: 0.3773 - top_k_categorical_accuracy: 0.8462 - val_loss: 2.2830 - val_categorical_accuracy: 0.4635 - val_top_k_categorical_accuracy: 0.9129\n",
            "Epoch 10/65\n",
            "36/36 - 0s - loss: 1.6726 - categorical_accuracy: 0.3960 - top_k_categorical_accuracy: 0.8700 - val_loss: 2.1682 - val_categorical_accuracy: 0.4809 - val_top_k_categorical_accuracy: 0.9203\n",
            "Epoch 11/65\n",
            "36/36 - 0s - loss: 1.6290 - categorical_accuracy: 0.4073 - top_k_categorical_accuracy: 0.8720 - val_loss: 2.0513 - val_categorical_accuracy: 0.4936 - val_top_k_categorical_accuracy: 0.9243\n",
            "Epoch 12/65\n",
            "36/36 - 0s - loss: 1.5672 - categorical_accuracy: 0.4351 - top_k_categorical_accuracy: 0.8873 - val_loss: 1.9274 - val_categorical_accuracy: 0.5003 - val_top_k_categorical_accuracy: 0.9290\n",
            "Epoch 13/65\n",
            "36/36 - 0s - loss: 1.5611 - categorical_accuracy: 0.4247 - top_k_categorical_accuracy: 0.8898 - val_loss: 1.8133 - val_categorical_accuracy: 0.5050 - val_top_k_categorical_accuracy: 0.9243\n",
            "Epoch 14/65\n",
            "36/36 - 0s - loss: 1.5163 - categorical_accuracy: 0.4498 - top_k_categorical_accuracy: 0.8960 - val_loss: 1.6973 - val_categorical_accuracy: 0.5198 - val_top_k_categorical_accuracy: 0.9297\n",
            "Epoch 15/65\n",
            "36/36 - 0s - loss: 1.4954 - categorical_accuracy: 0.4447 - top_k_categorical_accuracy: 0.9018 - val_loss: 1.5975 - val_categorical_accuracy: 0.5157 - val_top_k_categorical_accuracy: 0.9297\n",
            "Epoch 16/65\n",
            "36/36 - 0s - loss: 1.4554 - categorical_accuracy: 0.4649 - top_k_categorical_accuracy: 0.8967 - val_loss: 1.5068 - val_categorical_accuracy: 0.5218 - val_top_k_categorical_accuracy: 0.9303\n",
            "Epoch 17/65\n",
            "36/36 - 0s - loss: 1.4223 - categorical_accuracy: 0.4722 - top_k_categorical_accuracy: 0.9124 - val_loss: 1.4305 - val_categorical_accuracy: 0.5177 - val_top_k_categorical_accuracy: 0.9317\n",
            "Epoch 18/65\n",
            "36/36 - 0s - loss: 1.3926 - categorical_accuracy: 0.4838 - top_k_categorical_accuracy: 0.9169 - val_loss: 1.3750 - val_categorical_accuracy: 0.5298 - val_top_k_categorical_accuracy: 0.9350\n",
            "Epoch 19/65\n",
            "36/36 - 0s - loss: 1.3723 - categorical_accuracy: 0.4922 - top_k_categorical_accuracy: 0.9218 - val_loss: 1.3280 - val_categorical_accuracy: 0.5345 - val_top_k_categorical_accuracy: 0.9330\n",
            "Epoch 20/65\n",
            "36/36 - 0s - loss: 1.3337 - categorical_accuracy: 0.5049 - top_k_categorical_accuracy: 0.9269 - val_loss: 1.2937 - val_categorical_accuracy: 0.5365 - val_top_k_categorical_accuracy: 0.9377\n",
            "Epoch 21/65\n",
            "36/36 - 0s - loss: 1.3396 - categorical_accuracy: 0.5091 - top_k_categorical_accuracy: 0.9196 - val_loss: 1.2704 - val_categorical_accuracy: 0.5358 - val_top_k_categorical_accuracy: 0.9390\n",
            "Epoch 22/65\n",
            "36/36 - 0s - loss: 1.2991 - categorical_accuracy: 0.5178 - top_k_categorical_accuracy: 0.9313 - val_loss: 1.2496 - val_categorical_accuracy: 0.5419 - val_top_k_categorical_accuracy: 0.9390\n",
            "Epoch 23/65\n",
            "36/36 - 0s - loss: 1.3050 - categorical_accuracy: 0.5158 - top_k_categorical_accuracy: 0.9227 - val_loss: 1.2340 - val_categorical_accuracy: 0.5539 - val_top_k_categorical_accuracy: 0.9390\n",
            "Epoch 24/65\n",
            "36/36 - 0s - loss: 1.2822 - categorical_accuracy: 0.5140 - top_k_categorical_accuracy: 0.9351 - val_loss: 1.2227 - val_categorical_accuracy: 0.5486 - val_top_k_categorical_accuracy: 0.9364\n",
            "Epoch 25/65\n",
            "36/36 - 0s - loss: 1.2644 - categorical_accuracy: 0.5300 - top_k_categorical_accuracy: 0.9329 - val_loss: 1.2150 - val_categorical_accuracy: 0.5606 - val_top_k_categorical_accuracy: 0.9377\n",
            "Epoch 26/65\n",
            "36/36 - 0s - loss: 1.2406 - categorical_accuracy: 0.5382 - top_k_categorical_accuracy: 0.9333 - val_loss: 1.1993 - val_categorical_accuracy: 0.5599 - val_top_k_categorical_accuracy: 0.9390\n",
            "Epoch 27/65\n",
            "36/36 - 0s - loss: 1.2337 - categorical_accuracy: 0.5407 - top_k_categorical_accuracy: 0.9398 - val_loss: 1.1868 - val_categorical_accuracy: 0.5640 - val_top_k_categorical_accuracy: 0.9397\n",
            "Epoch 28/65\n",
            "36/36 - 0s - loss: 1.1857 - categorical_accuracy: 0.5522 - top_k_categorical_accuracy: 0.9447 - val_loss: 1.1822 - val_categorical_accuracy: 0.5673 - val_top_k_categorical_accuracy: 0.9377\n",
            "Epoch 29/65\n",
            "36/36 - 0s - loss: 1.1825 - categorical_accuracy: 0.5558 - top_k_categorical_accuracy: 0.9447 - val_loss: 1.1768 - val_categorical_accuracy: 0.5720 - val_top_k_categorical_accuracy: 0.9397\n",
            "Epoch 30/65\n",
            "36/36 - 0s - loss: 1.1569 - categorical_accuracy: 0.5638 - top_k_categorical_accuracy: 0.9482 - val_loss: 1.1727 - val_categorical_accuracy: 0.5673 - val_top_k_categorical_accuracy: 0.9424\n",
            "Epoch 31/65\n",
            "36/36 - 0s - loss: 1.1818 - categorical_accuracy: 0.5593 - top_k_categorical_accuracy: 0.9447 - val_loss: 1.1669 - val_categorical_accuracy: 0.5733 - val_top_k_categorical_accuracy: 0.9424\n",
            "Epoch 32/65\n",
            "36/36 - 0s - loss: 1.1300 - categorical_accuracy: 0.5700 - top_k_categorical_accuracy: 0.9529 - val_loss: 1.1633 - val_categorical_accuracy: 0.5767 - val_top_k_categorical_accuracy: 0.9424\n",
            "Epoch 33/65\n",
            "36/36 - 0s - loss: 1.1302 - categorical_accuracy: 0.5713 - top_k_categorical_accuracy: 0.9538 - val_loss: 1.1626 - val_categorical_accuracy: 0.5653 - val_top_k_categorical_accuracy: 0.9411\n",
            "Epoch 34/65\n",
            "36/36 - 0s - loss: 1.1218 - categorical_accuracy: 0.5807 - top_k_categorical_accuracy: 0.9522 - val_loss: 1.1526 - val_categorical_accuracy: 0.5780 - val_top_k_categorical_accuracy: 0.9431\n",
            "Epoch 35/65\n",
            "36/36 - 0s - loss: 1.1155 - categorical_accuracy: 0.5891 - top_k_categorical_accuracy: 0.9478 - val_loss: 1.1514 - val_categorical_accuracy: 0.5760 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 36/65\n",
            "36/36 - 0s - loss: 1.0833 - categorical_accuracy: 0.5871 - top_k_categorical_accuracy: 0.9551 - val_loss: 1.1411 - val_categorical_accuracy: 0.5847 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 37/65\n",
            "36/36 - 0s - loss: 1.0669 - categorical_accuracy: 0.6056 - top_k_categorical_accuracy: 0.9564 - val_loss: 1.1380 - val_categorical_accuracy: 0.5841 - val_top_k_categorical_accuracy: 0.9457\n",
            "Epoch 38/65\n",
            "36/36 - 0s - loss: 1.0427 - categorical_accuracy: 0.6073 - top_k_categorical_accuracy: 0.9596 - val_loss: 1.1350 - val_categorical_accuracy: 0.5847 - val_top_k_categorical_accuracy: 0.9464\n",
            "Epoch 39/65\n",
            "36/36 - 0s - loss: 1.0389 - categorical_accuracy: 0.6193 - top_k_categorical_accuracy: 0.9564 - val_loss: 1.1355 - val_categorical_accuracy: 0.5820 - val_top_k_categorical_accuracy: 0.9464\n",
            "Epoch 40/65\n",
            "36/36 - 0s - loss: 1.0256 - categorical_accuracy: 0.6216 - top_k_categorical_accuracy: 0.9600 - val_loss: 1.1334 - val_categorical_accuracy: 0.5867 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 41/65\n",
            "36/36 - 0s - loss: 1.0125 - categorical_accuracy: 0.6158 - top_k_categorical_accuracy: 0.9580 - val_loss: 1.1250 - val_categorical_accuracy: 0.5887 - val_top_k_categorical_accuracy: 0.9457\n",
            "Epoch 42/65\n",
            "36/36 - 0s - loss: 1.0097 - categorical_accuracy: 0.6167 - top_k_categorical_accuracy: 0.9647 - val_loss: 1.1219 - val_categorical_accuracy: 0.5968 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 43/65\n",
            "36/36 - 0s - loss: 0.9933 - categorical_accuracy: 0.6280 - top_k_categorical_accuracy: 0.9618 - val_loss: 1.1203 - val_categorical_accuracy: 0.5968 - val_top_k_categorical_accuracy: 0.9464\n",
            "Epoch 44/65\n",
            "36/36 - 0s - loss: 0.9748 - categorical_accuracy: 0.6362 - top_k_categorical_accuracy: 0.9651 - val_loss: 1.1204 - val_categorical_accuracy: 0.5968 - val_top_k_categorical_accuracy: 0.9471\n",
            "Epoch 45/65\n",
            "36/36 - 0s - loss: 0.9668 - categorical_accuracy: 0.6400 - top_k_categorical_accuracy: 0.9658 - val_loss: 1.1166 - val_categorical_accuracy: 0.6048 - val_top_k_categorical_accuracy: 0.9484\n",
            "Epoch 46/65\n",
            "36/36 - 0s - loss: 0.9681 - categorical_accuracy: 0.6338 - top_k_categorical_accuracy: 0.9696 - val_loss: 1.1187 - val_categorical_accuracy: 0.5948 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 47/65\n",
            "36/36 - 0s - loss: 0.9306 - categorical_accuracy: 0.6529 - top_k_categorical_accuracy: 0.9680 - val_loss: 1.1188 - val_categorical_accuracy: 0.5954 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 48/65\n",
            "36/36 - 0s - loss: 0.9240 - categorical_accuracy: 0.6624 - top_k_categorical_accuracy: 0.9687 - val_loss: 1.1097 - val_categorical_accuracy: 0.6015 - val_top_k_categorical_accuracy: 0.9471\n",
            "Epoch 49/65\n",
            "36/36 - 0s - loss: 0.9024 - categorical_accuracy: 0.6598 - top_k_categorical_accuracy: 0.9716 - val_loss: 1.1101 - val_categorical_accuracy: 0.5988 - val_top_k_categorical_accuracy: 0.9471\n",
            "Epoch 50/65\n",
            "36/36 - 0s - loss: 0.9192 - categorical_accuracy: 0.6524 - top_k_categorical_accuracy: 0.9687 - val_loss: 1.1116 - val_categorical_accuracy: 0.5981 - val_top_k_categorical_accuracy: 0.9484\n",
            "Epoch 51/65\n",
            "36/36 - 0s - loss: 0.9042 - categorical_accuracy: 0.6689 - top_k_categorical_accuracy: 0.9693 - val_loss: 1.1110 - val_categorical_accuracy: 0.6008 - val_top_k_categorical_accuracy: 0.9471\n",
            "Epoch 52/65\n",
            "36/36 - 0s - loss: 0.8723 - categorical_accuracy: 0.6780 - top_k_categorical_accuracy: 0.9733 - val_loss: 1.1086 - val_categorical_accuracy: 0.6068 - val_top_k_categorical_accuracy: 0.9444\n",
            "Epoch 53/65\n",
            "36/36 - 0s - loss: 0.8842 - categorical_accuracy: 0.6631 - top_k_categorical_accuracy: 0.9742 - val_loss: 1.1110 - val_categorical_accuracy: 0.6075 - val_top_k_categorical_accuracy: 0.9464\n",
            "Epoch 54/65\n",
            "36/36 - 0s - loss: 0.8550 - categorical_accuracy: 0.6813 - top_k_categorical_accuracy: 0.9751 - val_loss: 1.1152 - val_categorical_accuracy: 0.6068 - val_top_k_categorical_accuracy: 0.9431\n",
            "Epoch 55/65\n",
            "36/36 - 0s - loss: 0.8617 - categorical_accuracy: 0.6798 - top_k_categorical_accuracy: 0.9753 - val_loss: 1.1106 - val_categorical_accuracy: 0.6055 - val_top_k_categorical_accuracy: 0.9457\n",
            "Epoch 56/65\n",
            "36/36 - 0s - loss: 0.8445 - categorical_accuracy: 0.6878 - top_k_categorical_accuracy: 0.9753 - val_loss: 1.1183 - val_categorical_accuracy: 0.6062 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 57/65\n",
            "36/36 - 0s - loss: 0.8406 - categorical_accuracy: 0.6880 - top_k_categorical_accuracy: 0.9742 - val_loss: 1.1203 - val_categorical_accuracy: 0.6115 - val_top_k_categorical_accuracy: 0.9464\n",
            "Epoch 58/65\n",
            "36/36 - 0s - loss: 0.8308 - categorical_accuracy: 0.6933 - top_k_categorical_accuracy: 0.9778 - val_loss: 1.1198 - val_categorical_accuracy: 0.6042 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 59/65\n",
            "36/36 - 0s - loss: 0.8319 - categorical_accuracy: 0.6944 - top_k_categorical_accuracy: 0.9784 - val_loss: 1.1135 - val_categorical_accuracy: 0.6129 - val_top_k_categorical_accuracy: 0.9451\n",
            "Epoch 60/65\n",
            "36/36 - 0s - loss: 0.8029 - categorical_accuracy: 0.7060 - top_k_categorical_accuracy: 0.9724 - val_loss: 1.1124 - val_categorical_accuracy: 0.6202 - val_top_k_categorical_accuracy: 0.9457\n",
            "Epoch 61/65\n",
            "36/36 - 0s - loss: 0.7757 - categorical_accuracy: 0.7113 - top_k_categorical_accuracy: 0.9771 - val_loss: 1.1185 - val_categorical_accuracy: 0.6122 - val_top_k_categorical_accuracy: 0.9471\n",
            "Epoch 62/65\n",
            "36/36 - 0s - loss: 0.7629 - categorical_accuracy: 0.7122 - top_k_categorical_accuracy: 0.9798 - val_loss: 1.1133 - val_categorical_accuracy: 0.6162 - val_top_k_categorical_accuracy: 0.9471\n",
            "Epoch 63/65\n",
            "36/36 - 0s - loss: 0.7691 - categorical_accuracy: 0.7100 - top_k_categorical_accuracy: 0.9789 - val_loss: 1.1156 - val_categorical_accuracy: 0.6109 - val_top_k_categorical_accuracy: 0.9471\n",
            "Epoch 64/65\n",
            "36/36 - 0s - loss: 0.7611 - categorical_accuracy: 0.7178 - top_k_categorical_accuracy: 0.9798 - val_loss: 1.1160 - val_categorical_accuracy: 0.6202 - val_top_k_categorical_accuracy: 0.9478\n",
            "Epoch 65/65\n",
            "36/36 - 0s - loss: 0.7518 - categorical_accuracy: 0.7193 - top_k_categorical_accuracy: 0.9807 - val_loss: 1.1166 - val_categorical_accuracy: 0.6222 - val_top_k_categorical_accuracy: 0.9491\n",
            "model training is completed.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 300)               77100     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 15)                4515      \n",
            "=================================================================\n",
            "Total params: 4,937,167\n",
            "Trainable params: 4,930,604\n",
            "Non-trainable params: 6,563\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5_input (InputLayer)   [(None, 4096)]            0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 300)               77100     \n",
            "=================================================================\n",
            "Total params: 4,932,652\n",
            "Trainable params: 4,930,604\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "-> zsl model is saved.\n",
            "\n",
            "ZERO SHOT LEARNING SCORE\n",
            "-> Top-5 Accuracy: 0.74\n",
            "-> Top-3 Accuracy: 0.34\n",
            "-> Top-1 Accuracy: 0.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvxVrhv2FhHS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRmiDQevFRxf"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.neighbors import KDTree\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "from feature_extractor import get_model, get_features\n",
        "from train import load_keras_model\n",
        "\n",
        "\n",
        "WORD2VECPATH    = \"../data/class_vectors.npy\"\n",
        "MODELPATH       = \"../model/\"\n",
        "\n",
        "def main(argv):\n",
        "\n",
        "    if len(argv) != 1:\n",
        "        print(\"Usage: python3 detect_object.py input-image-path\")\n",
        "        exit()\n",
        "\n",
        "    # READ IMAGE\n",
        "    IMAGEPATH = argv[0]\n",
        "    img         = Image.open(IMAGEPATH).resize((224, 224))\n",
        "\n",
        "    # LOAD PRETRAINED VGG16 MODEL FOR FEATURE EXTRACTION\n",
        "    vgg_model   = get_model()\n",
        "    # EXTRACT IMAGE FEATURE\n",
        "    img_feature = get_features(vgg_model, img)\n",
        "    # L2 NORMALIZE FEATURE\n",
        "    img_feature = normalize(img_feature, norm='l2')\n",
        "\n",
        "    # LOAD ZERO-SHOT MODEL\n",
        "    model       = load_keras_model(model_path=MODELPATH)\n",
        "    # MAKE PREDICTION\n",
        "    pred        = model.predict(img_feature)\n",
        "\n",
        "    # LOAD CLASS WORD2VECS\n",
        "    class_vectors       = sorted(np.load(WORD2VECPATH allow_pickle=True), key=lambda x: x[0])\n",
        "    classnames, vectors = zip(*class_vectors)\n",
        "    classnames          = list(classnames)\n",
        "    vectors             = np.asarray(vectors, dtype=np.float)\n",
        "\n",
        "    # PLACE WORD2VECS IN KDTREE\n",
        "    tree                = KDTree(vectors)\n",
        "    # FIND CLOSEST WORD2VEC and GET PREDICTION RESULT\n",
        "    dist, index         = tree.query(pred, k=5)\n",
        "    pred_labels         = [classnames[idx] for idx in index[0]]\n",
        "\n",
        "    # PRINT RESULT\n",
        "    print()\n",
        "    print(\"--- Top-5 Prediction ---\")\n",
        "    for i, classname in enumerate(pred_labels):\n",
        "        print(\"%d- %s\" %(i+1, classname))\n",
        "    print()\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(sys.argv[1:])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}